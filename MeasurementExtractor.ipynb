{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from parsi_io.modules.number_extractor import NumberExtractor\n",
    "\n",
    "from hazm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeasurementExtractor:\n",
    "    #a dictionary to map qunatity's name from english to farsi\n",
    "    quantity_name_translator = {\n",
    "        \"length\": \"طول\",\n",
    "        \"mass\": \"وزن\",\n",
    "        \"pressure\": \"فشار\",\n",
    "        \"volume\": \"حجم\",\n",
    "        \"temperature\": \"دما\",\n",
    "        \"area\":\"مساحت\",\n",
    "        \"speed\":\"سرعت\",\n",
    "        \"force\":\"نیرو\",\n",
    "        \"energy\":\"انرژی\",\n",
    "        \"power\":\"توان\",\n",
    "        \"torque\":\"گشتاور\",\n",
    "        \"time\":\"زمان\",\n",
    "        \"density\":\"چگالی\",\n",
    "        \"frequency\":\"فرکانس\",\n",
    "        \"degree\":\"زاویه\",\n",
    "        \"acceleration\":\"شتاب\",\n",
    "        \"debi\":\"شارش جرمی\",\n",
    "        \"debi-v\":\"شارش حجمی\",\n",
    "        \"data-storage\":\"ذخیره دیجیتال\",\n",
    "        \"data-transfer\":\"انتقال داده\",\n",
    "        \"wildcard\" : \"عام\"\n",
    "    }\n",
    "\n",
    "    extractor = NumberExtractor()\n",
    "    #loading units data and replacing \"NaN\" values with 0\n",
    "    units_dataframe = pd.read_csv(\"Units.csv\",header=None)\n",
    "    units_dataframe = units_dataframe.replace(np.nan, 0)\n",
    "\n",
    "\n",
    "    # loading pre-unit words which are used in \"pre-unit word + [decimal frachtion] + unit\" pattern.\n",
    "    preunits_dataframe = pd.read_csv(\"PreUnitWords.csv\",header=None)\n",
    "    preunits_dataframe = preunits_dataframe.transpose()\n",
    "\n",
    "\n",
    "    # loading pre-unit words which are used in \"pre-unit word + [decimal frachtion] + unit\" pattern.\n",
    "    decimal_fractions_dataframe = pd.read_csv(\"DecimalFractions.csv\",header=None)\n",
    "    decimal_fractions_dataframe = decimal_fractions_dataframe.transpose()\n",
    "\n",
    "    decimal_fractions_list = decimal_fractions_dataframe.values.tolist()\n",
    "    decimal_fractions_joined = \"|\".join(decimal_fractions_list[0])    \n",
    "\n",
    "    adjectives_dataframe = pd.read_csv(\"Adjectives.csv\",header=0)\n",
    "    pattern_3_adjectives = []\n",
    "    pattern_4_adjectives = []\n",
    "    pattern_4_adjective_to_type = {}\n",
    "    adjectives_dataframe = adjectives_dataframe.reset_index()  # make sure indexes pair with number of rows\n",
    "    for index, row in adjectives_dataframe.iterrows():\n",
    "        if row['valid for pattern 3'] == 1:\n",
    "            pattern_3_adjectives+= [row['adjective']]\n",
    "        if row['valid for pattern 4'] == 1:\n",
    "            pattern_4_adjectives+= [row['adjective']]\n",
    "            pattern_4_adjective_to_type[row['adjective']]= row['pattern 4 type']        \n",
    "    pattern_3_adjectives_joined = \"|\".join(pattern_3_adjectives)\n",
    "    pattern_4_adjectives_joined = \"|\".join(pattern_4_adjectives)\n",
    "\n",
    "    keywords_dataframe = pd.read_csv(\"Keywords.csv\",header=0)\n",
    "    \n",
    "    all_keywords = []\n",
    "    pattern_1_keywords = []\n",
    "    pattern_1_keyword_to_type = {}\n",
    "    keywords_dataframe = keywords_dataframe.reset_index()  # make sure indexes pair with number of rows\n",
    "    for index, row in keywords_dataframe.iterrows():\n",
    "        all_keywords+= [row['keyword']]\n",
    "        pattern_1_keywords+= [row['keyword']]\n",
    "        pattern_1_keyword_to_type[row['keyword']]= quantity_name_translator[row['type']]\n",
    "    pattern_1_keywords_joined = \"|\".join(pattern_1_keywords)\n",
    "    all_keywords_joined = \"|\".join(all_keywords)\n",
    "\n",
    "    #creating a dictionary of units which key corresponds quantity name and value corresponds list of units related to that quantity\n",
    "    units_dict = {}\n",
    "    for index, row in units_dataframe.iterrows():\n",
    "        qunantity_name = row[0]\n",
    "        quantity_units = row[1:].tolist()\n",
    "        #removing 0 values\n",
    "        quantity_units = list(filter(lambda a: a != 0, quantity_units))\n",
    "        units_dict [qunantity_name] = quantity_units\n",
    "\n",
    "\n",
    "    #joining all units sorted by length in descending order\n",
    "    all_units = []\n",
    "    for key, value in units_dict.items():\n",
    "        all_units += value\n",
    "    sorted_units = sorted(all_units, key=len, reverse = True)\n",
    "    sorted_units_joined = \"|\".join(sorted_units)\n",
    "    \n",
    "    preunits_list = preunits_dataframe.values.tolist()\n",
    "    preunits_joined = \"|\".join(preunits_list[0])\n",
    "\n",
    "    # We don't need this function anymore.\n",
    "    # a function that joins all units with or (\"|\")\n",
    "    units_joined = \"\"\n",
    "    for key, value in units_dict.items():\n",
    "        units_joined += \"|\".join(value)\n",
    "        units_joined += \"|\"\n",
    "    units_joined = units_joined[:-1]\n",
    "\n",
    "    def extract_noun_phrases(input_str):\n",
    "        tagger = POSTagger(model='resources/postagger.model')\n",
    "        chunker = Chunker(model='resources/chunker.model')\n",
    "        tagged = tagger.tag(word_tokenize(input_str))\n",
    "        phrases = tree2brackets(chunker.parse(tagged))\n",
    "        chunks = re.split('] ', phrases)\n",
    "        noun_phrases = []\n",
    "        pharases_span = []\n",
    "        for i in range(len(chunks)):\n",
    "            t = ()\n",
    "            m = re.search('.*NP',chunks[i][1:])\n",
    "            if m != None:\n",
    "                match = m.group()\n",
    "                np = match[:-3]\n",
    "                t += (input_str.find(np), input_str.find(np)+len(np))\n",
    "                pharases_span.append(t)\n",
    "                noun_phrases.append(np)\n",
    "        return noun_phrases, pharases_span\n",
    "\n",
    "    def get_keyword_type(match):\n",
    "        determined_type = \"\"\n",
    "        type_indicator = \"\"\n",
    "        for part in match.group():\n",
    "            type_indicator+=part\n",
    "            if type_indicator in MeasurementExtractor.pattern_1_keyword_to_type:\n",
    "                determined_type = MeasurementExtractor.pattern_1_keyword_to_type[type_indicator]\n",
    "        return determined_type\n",
    "\n",
    "    def get_adjective_type(match):\n",
    "        determined_type = \"\"\n",
    "        type_indicator = \"\"\n",
    "        for part in match.group():\n",
    "            type_indicator+=part\n",
    "            if type_indicator in MeasurementExtractor.pattern_4_adjective_to_type:\n",
    "                determined_type = MeasurementExtractor.pattern_4_adjective_to_type[type_indicator]\n",
    "        return determined_type\n",
    "\n",
    "\n",
    "    # a function that gets the unit and returns corresponding quantity type in persian\n",
    "    def get_quantity_type(unit):\n",
    "        for key, value in MeasurementExtractor.units_dict.items():\n",
    "            if unit in value:\n",
    "                return MeasurementExtractor.quantity_name_translator[key]\n",
    "        return 0\n",
    "\n",
    "    def run(input_str):\n",
    "        output = match_keyword_adjective_pattern(input_str)\n",
    "        output += match_keyword_amount_pattern (input_str)\n",
    "        output += match_sole_adjecive_pattern (input_str)\n",
    "        output += match_amount_unit_item_pattern (input_str)\n",
    "        output += match_preunit_decimal_unit_pattern (input_str)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_keyword_adjective_pattern (input_str):\n",
    "    all_matches = re.findall(f'({MeasurementExtractor.all_keywords_joined})+\\s*({MeasurementExtractor.pattern_3_adjectives_joined})+',input_str)\n",
    "    \n",
    "    i = 0\n",
    "    output = [{} for sub in range(len(all_matches))]\n",
    "    for match in re.finditer(f'({MeasurementExtractor.all_keywords_joined})+\\s*({MeasurementExtractor.pattern_3_adjectives_joined})+',input_str):        \n",
    "        output[i]['type'] = MeasurementExtractor.get_keyword_type(match)\n",
    "        output[i]['unit'] = \"\"\n",
    "        output[i]['amount'] = \"\"\n",
    "        output[i]['marker'] = match.group()\n",
    "        output[i]['span'] = match.span()\n",
    "        i += 1\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'طول', 'unit': '', 'amount': '', 'marker': 'عرض کم', 'span': (14, 20)}]\n"
     ]
    }
   ],
   "source": [
    "input = \"رودخانه‌ای با عرض کم دیدم\"\n",
    "print(match_keyword_adjective_pattern(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_keyword_amount_pattern (input_str):\n",
    "    values = MeasurementExtractor.extractor.run(input_str)\n",
    "    if len(values) > 0:\n",
    "        phrase_amount_dict = {}\n",
    "        for value in values:\n",
    "            phrase_amount_dict[value['phrase']] = value['value'] \n",
    "        phrases_joined = \"|\".join(phrase_amount_dict.keys())\n",
    "\n",
    "        all_matches = re.findall(f'({MeasurementExtractor.pattern_1_keywords_joined})+\\s*({phrases_joined})+',input_str)\n",
    "\n",
    "        i = 0\n",
    "        output = [{} for sub in range(len(all_matches))]\n",
    "        for match in re.finditer(f'({MeasurementExtractor.pattern_1_keywords_joined})+\\s*({phrases_joined})+',input_str):\n",
    "            output[i]['type'] = MeasurementExtractor.get_keyword_type(match)\n",
    "            output[i]['unit'] = \"\"\n",
    "            output[i]['amount'] = phrase_amount_dict[all_matches[i][1]]\n",
    "            output[i]['marker'] = match.group()\n",
    "            output[i]['span'] = match.span()\n",
    "            i += 1\n",
    "    else:\n",
    "        output = []\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'طول', 'unit': '', 'amount': 4.0, 'marker': 'ضلع 4', 'span': (14, 19)}, {'type': 'طول', 'unit': '', 'amount': 12.0, 'marker': 'طول 12', 'span': (31, 37)}]\n"
     ]
    }
   ],
   "source": [
    "input = \"خانه اتاقی به ضلع 4 و حیاطی با طول 12 دارد\"\n",
    "print(match_keyword_amount_pattern(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_sole_adjecive_pattern (input_str):\n",
    "    all_matches = re.findall(f'({MeasurementExtractor.pattern_4_adjectives_joined})',input_str)\n",
    "    \n",
    "    i = 0\n",
    "    output = [{} for sub in range(len(all_matches))]\n",
    "    for match in re.finditer(f'({MeasurementExtractor.pattern_4_adjectives_joined})',input_str):\n",
    "        output[i]['type'] = MeasurementExtractor.get_adjective_type(match)\n",
    "        output[i]['unit'] = \"\"\n",
    "        output[i]['amount'] = \"\"\n",
    "        output[i]['marker'] = match.group()\n",
    "        output[i]['span'] = match.span()\n",
    "        i += 1\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'speed', 'unit': '', 'amount': '', 'marker': 'سریع', 'span': (0, 4)}]\n"
     ]
    }
   ],
   "source": [
    "input = \"سریع حرکت کرد\"\n",
    "print(match_sole_adjecive_pattern(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A function that detects quantities which follow \"amount + unit\" pattern.\n",
    "\"\"\"\n",
    "\n",
    "def match_amount_unit_item_pattern (input_str):\n",
    "    nphrases,np_s = MeasurementExtractor.extract_noun_phrases(input_str)\n",
    "    values = MeasurementExtractor.extractor.run(input_str)\n",
    "    if len(values) > 0:\n",
    "        phrase_amount_dict = {}\n",
    "        for value in values:\n",
    "            phrase_amount_dict[value['phrase']] = value['value'] \n",
    "        phrases_joined = \"|\".join(phrase_amount_dict.keys())\n",
    "            \n",
    "        all_matches = re.findall(f'({phrases_joined})+\\s*({MeasurementExtractor.sorted_units_joined})+',input_str)\n",
    "        i = 0\n",
    "        output = [{} for sub in range(len(all_matches))]\n",
    "        for match in re.finditer(f'({phrases_joined})+\\s*({MeasurementExtractor.sorted_units_joined})+',input_str):\n",
    "            #comment to be added :)) \n",
    "            marker = match.group()\n",
    "            j=0\n",
    "            span = match.span()\n",
    "            for s in np_s: \n",
    "                if s[0]<=match.span()[0] and s[1]>=match.span()[1]:\n",
    "                    start = match.span()[0]\n",
    "                    end = s[1]\n",
    "                    marker = input_str[start:end]\n",
    "                    span = (start, end)\n",
    "                j+=1\n",
    "            output[i]['type'] = MeasurementExtractor.get_quantity_type(all_matches[i][1])\n",
    "            output[i]['item'] = marker.replace(match.group(),'')\n",
    "            output[i]['amount'] = phrase_amount_dict[all_matches[i][0]]\n",
    "            output[i]['unit'] = all_matches[i][1]\n",
    "            output[i]['marker'] = marker\n",
    "            output[i]['span'] = span\n",
    "            i += 1\n",
    "    else:\n",
    "        output = []\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wapiti'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/3191783132.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# amount + unit examples:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"علی سه متر پارچه و دو کیلوگرم آرد خرید و یک ساعت صبر کرد.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatch_amount_unit_pattern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"2 Gb\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatch_amount_unit_pattern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/1035321505.py\u001b[0m in \u001b[0;36mmatch_amount_unit_pattern\u001b[1;34m(input_str)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmatch_amount_unit_pattern\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mnphrases\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMeasurementExtractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_noun_phrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMeasurementExtractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mphrase_amount_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/3680453740.py\u001b[0m in \u001b[0;36mextract_noun_phrases\u001b[1;34m(input_str)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextract_noun_phrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPOSTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'resources/postagger.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0mchunker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChunker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'resources/chunker.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mtagged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\hazm\\SequenceTagger.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, patterns, **options)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                 \u001b[1;32mfrom\u001b[0m \u001b[0mwapiti\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wapiti'"
     ]
    }
   ],
   "source": [
    "# amount + unit examples:\n",
    "input = \"علی سه متر پارچه و دو کیلوگرم آرد خرید و یک ساعت صبر کرد.\"\n",
    "print(match_amount_unit_item_pattern(input))\n",
    "input = \"2 Gb\"\n",
    "print(match_amount_unit_item_pattern(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A function that detects quantities which follow \"pre-unit words such as \"چند\" + \n",
    "                                                [decimal fractions (ده-صد-هزار و ...)] + \n",
    "                                                unit\" pattern.\n",
    "\"\"\"\n",
    "def match_preunit_decimal_unit_pattern(input_str):\n",
    "    \n",
    "    all_matches = re.findall(f'({MeasurementExtractor.preunits_joined})+\\s*({MeasurementExtractor.decimal_fractions_joined})?\\s*({MeasurementExtractor.units_joined})+',input_str)\n",
    "    i = 0\n",
    "    output = [{} for sub in range(len(all_matches))]\n",
    "    for match in re.finditer(f'({MeasurementExtractor.preunits_joined})+\\s*({MeasurementExtractor.decimal_fractions_joined})?\\s*({MeasurementExtractor.units_joined})+',input_str):\n",
    "        output[i]['type'] = MeasurementExtractor.get_quantity_type(all_matches[i][2])\n",
    "        output[i]['amount'] = ''\n",
    "        output[i]['unit'] = all_matches[i][2]\n",
    "        output[i]['marker'] = match.group()\n",
    "        output[i]['span'] = match.span()\n",
    "        i += 1\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'وزن', 'amount': '', 'unit': 'تن', 'marker': 'چند صد هزار تن', 'span': (0, 14)}]\n"
     ]
    }
   ],
   "source": [
    "# pre-unit word + [decimal fraction] + unit examples:\n",
    "input = \"چند صد هزار تن گوشت وارداتی\"\n",
    "print(match_preunit_decimal_unit_pattern(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wapiti'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/1786597239.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#bug solved:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatch_amount_unit_pattern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"دو فوت بر ثانیه\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/1035321505.py\u001b[0m in \u001b[0;36mmatch_amount_unit_pattern\u001b[1;34m(input_str)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmatch_amount_unit_pattern\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mnphrases\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMeasurementExtractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_noun_phrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMeasurementExtractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mphrase_amount_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/3680453740.py\u001b[0m in \u001b[0;36mextract_noun_phrases\u001b[1;34m(input_str)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextract_noun_phrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPOSTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'resources/postagger.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0mchunker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChunker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'resources/chunker.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mtagged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\hazm\\SequenceTagger.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, patterns, **options)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                 \u001b[1;32mfrom\u001b[0m \u001b[0mwapiti\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wapiti'"
     ]
    }
   ],
   "source": [
    "#bug solved:\n",
    "print(match_amount_unit_item_pattern(\"دو فوت بر ثانیه\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wapiti'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/1600211070.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"چند صد هزار تن گوشت وارداتی خرید و از رودخانه‌ای به عرض کم عبور داد تا 3 کلیگرم آرد بخرد\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMeasurementExtractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/3680453740.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(input_str)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmatch_keyword_amount_pattern\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmatch_sole_adjecive_pattern\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmatch_amount_unit_pattern\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmatch_preunit_decimal_unit_pattern\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/1035321505.py\u001b[0m in \u001b[0;36mmatch_amount_unit_pattern\u001b[1;34m(input_str)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmatch_amount_unit_pattern\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mnphrases\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMeasurementExtractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_noun_phrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMeasurementExtractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mphrase_amount_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/3680453740.py\u001b[0m in \u001b[0;36mextract_noun_phrases\u001b[1;34m(input_str)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextract_noun_phrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPOSTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'resources/postagger.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0mchunker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChunker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'resources/chunker.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mtagged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\hazm\\SequenceTagger.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, patterns, **options)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                 \u001b[1;32mfrom\u001b[0m \u001b[0mwapiti\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wapiti'"
     ]
    }
   ],
   "source": [
    "input = \"چند صد هزار تن گوشت وارداتی خرید و از رودخانه‌ای به عرض کم عبور داد تا 3 کلیگرم آرد بخرد\"\n",
    "print(MeasurementExtractor.run(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wapiti'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/3841677189.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# amount + unit examples:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minput1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"دو کیلوگرم آرد خرید . یک ساعت صبر کرد.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatch_amount_unit_pattern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minput2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"۲ گیگا بایت اینترنت رایگان گرفت\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/1035321505.py\u001b[0m in \u001b[0;36mmatch_amount_unit_pattern\u001b[1;34m(input_str)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmatch_amount_unit_pattern\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mnphrases\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMeasurementExtractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_noun_phrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMeasurementExtractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mphrase_amount_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11648/3680453740.py\u001b[0m in \u001b[0;36mextract_noun_phrases\u001b[1;34m(input_str)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextract_noun_phrases\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPOSTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'resources/postagger.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0mchunker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChunker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'resources/chunker.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[0mtagged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\mlenv\\lib\\site-packages\\hazm\\SequenceTagger.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, patterns, **options)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                 \u001b[1;32mfrom\u001b[0m \u001b[0mwapiti\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatterns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wapiti'"
     ]
    }
   ],
   "source": [
    "# amount + unit examples:\n",
    "input1 = \"دو کیلوگرم آرد خرید . یک ساعت صبر کرد.\"\n",
    "print(match_amount_unit_item_pattern(input1))\n",
    "\n",
    "input2 = \"۲ گیگا بایت اینترنت رایگان گرفت\"\n",
    "print(match_amount_unit_item_pattern(input2))\n",
    "\n",
    "input4 = \"باتری خود را هشتاد و پنج صدم وات شارژ کرد.\"\n",
    "print(match_amount_unit_item_pattern(input4))\n",
    "\n",
    "input5 = \"علی سه کیلوگرم آرد را خرید\"\n",
    "print(match_amount_unit_item_pattern(input5))\n",
    "\n",
    "input6 = \"سه مثقال طلا خرید و فروخت.\"\n",
    "print(match_amount_unit_item_pattern(input6))\n",
    "\n",
    "\n",
    "# test cases:\n",
    "t1 = \"علی ۳.۵ کیلوگرم آرد خرید و باتری خود را هشتاد و پنج صدم وات شارژ کرد.\"\n",
    "print(match_amount_unit_item_pattern(t1))\n",
    "\n",
    "t2 = \"شهاب سنگی به تندی ۱۵ km/s وارد جو زمین شد.\"\n",
    "print(match_amount_unit_item_pattern(t2))\n",
    "\n",
    "# t3 = \"یک خودرو با سرعت زیاد از ما سبقت گرفت\"\n",
    "\n",
    "\n",
    "# buggy examples:\n",
    "# in b1, it doesn't get نان as an item.\n",
    "b1 = 'سه کیلوگرم نان را خورد و باتری خود را هشتاد و پنج صدم وات شارژ کرد.'\n",
    "print(match_amount_unit_item_pattern(b1))\n",
    "\n",
    "b2 = \"علی سه کیلوگرم آرد خرید\"\n",
    "print(match_amount_unit_item_pattern(b2))\n",
    "\n",
    "\n",
    "# pre-unit word + [decimal fraction] + unit examples:\n",
    "#input3 = \"چند صد هزار تن گوشت وارداتی\"\n",
    "#print(match_preunit_decimal_unit_pattern(input3))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7715a419f54c4ba9091f066295a2740e8ed643bbb4249e443bc16748afed6227"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
